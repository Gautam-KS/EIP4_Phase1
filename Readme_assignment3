--------------------------------------------------------------------------------------------------------------------------
The final validation accuracy for base network:   val_acc: 0.8274
---------------------------------------------------------------------------------------------------------------------------
390/390 [==============================] - 28s 73ms/step - loss: 1.8351 - acc: 0.2999 - val_loss: 1.4254 - val_acc: 0.4862
Epoch 2/50
390/390 [==============================] - 20s 52ms/step - loss: 1.3252 - acc: 0.5227 - val_loss: 1.0830 - val_acc: 0.6085
Epoch 3/50
390/390 [==============================] - 20s 52ms/step - loss: 1.0833 - acc: 0.6174 - val_loss: 0.9882 - val_acc: 0.6477
Epoch 4/50
390/390 [==============================] - 20s 52ms/step - loss: 0.9441 - acc: 0.6707 - val_loss: 0.8405 - val_acc: 0.7098
Epoch 5/50
390/390 [==============================] - 20s 52ms/step - loss: 0.8476 - acc: 0.7092 - val_loss: 0.7720 - val_acc: 0.7357
Epoch 6/50
390/390 [==============================] - 20s 52ms/step - loss: 0.7794 - acc: 0.7344 - val_loss: 0.7039 - val_acc: 0.7609
Epoch 7/50
390/390 [==============================] - 20s 52ms/step - loss: 0.7180 - acc: 0.7548 - val_loss: 0.6970 - val_acc: 0.7586
Epoch 8/50
390/390 [==============================] - 20s 52ms/step - loss: 0.6842 - acc: 0.7684 - val_loss: 0.6505 - val_acc: 0.7761
Epoch 9/50
390/390 [==============================] - 20s 51ms/step - loss: 0.6513 - acc: 0.7783 - val_loss: 0.6079 - val_acc: 0.7953
Epoch 10/50
390/390 [==============================] - 20s 52ms/step - loss: 0.6203 - acc: 0.7884 - val_loss: 0.6159 - val_acc: 0.7922
Epoch 11/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5963 - acc: 0.7980 - val_loss: 0.6811 - val_acc: 0.7744
Epoch 12/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5755 - acc: 0.8045 - val_loss: 0.6169 - val_acc: 0.7946
Epoch 13/50
390/390 [==============================] - 20s 51ms/step - loss: 0.5684 - acc: 0.8089 - val_loss: 0.6078 - val_acc: 0.7970
Epoch 14/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5386 - acc: 0.8167 - val_loss: 0.5818 - val_acc: 0.8073
Epoch 15/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5261 - acc: 0.8214 - val_loss: 0.5952 - val_acc: 0.7995
Epoch 16/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5026 - acc: 0.8278 - val_loss: 0.5605 - val_acc: 0.8168
Epoch 17/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4982 - acc: 0.8303 - val_loss: 0.5713 - val_acc: 0.8099
Epoch 18/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4826 - acc: 0.8350 - val_loss: 0.5944 - val_acc: 0.8084
Epoch 19/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4714 - acc: 0.8386 - val_loss: 0.5732 - val_acc: 0.8135
Epoch 20/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4610 - acc: 0.8444 - val_loss: 0.5714 - val_acc: 0.8133
Epoch 21/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4513 - acc: 0.8452 - val_loss: 0.5603 - val_acc: 0.8217
Epoch 22/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4410 - acc: 0.8485 - val_loss: 0.5961 - val_acc: 0.8038
Epoch 23/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4353 - acc: 0.8520 - val_loss: 0.5998 - val_acc: 0.8113
Epoch 24/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4209 - acc: 0.8548 - val_loss: 0.5843 - val_acc: 0.8089
Epoch 25/50
390/390 [==============================] - 20s 51ms/step - loss: 0.4221 - acc: 0.8573 - val_loss: 0.5532 - val_acc: 0.8235
Epoch 26/50
390/390 [==============================] - 20s 51ms/step - loss: 0.4215 - acc: 0.8558 - val_loss: 0.5766 - val_acc: 0.8164
Epoch 27/50
390/390 [==============================] - 20s 51ms/step - loss: 0.4095 - acc: 0.8608 - val_loss: 0.5770 - val_acc: 0.8178
Epoch 28/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3980 - acc: 0.8647 - val_loss: 0.5789 - val_acc: 0.8192
Epoch 29/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3958 - acc: 0.8670 - val_loss: 0.5778 - val_acc: 0.8185
Epoch 30/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3987 - acc: 0.8647 - val_loss: 0.5792 - val_acc: 0.8191
Epoch 31/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3897 - acc: 0.8674 - val_loss: 0.5966 - val_acc: 0.8172
Epoch 32/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3736 - acc: 0.8744 - val_loss: 0.5657 - val_acc: 0.8228
Epoch 33/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3730 - acc: 0.8744 - val_loss: 0.5401 - val_acc: 0.8324
Epoch 34/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3641 - acc: 0.8750 - val_loss: 0.5841 - val_acc: 0.8235
Epoch 35/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3534 - acc: 0.8793 - val_loss: 0.5956 - val_acc: 0.8179
Epoch 36/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3631 - acc: 0.8774 - val_loss: 0.6106 - val_acc: 0.8179
Epoch 37/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3594 - acc: 0.8773 - val_loss: 0.5875 - val_acc: 0.8198
Epoch 38/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3593 - acc: 0.8772 - val_loss: 0.5762 - val_acc: 0.8190
Epoch 39/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3491 - acc: 0.8824 - val_loss: 0.5656 - val_acc: 0.8192
Epoch 40/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3486 - acc: 0.8815 - val_loss: 0.5966 - val_acc: 0.8217
Epoch 41/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3358 - acc: 0.8866 - val_loss: 0.6118 - val_acc: 0.8152
Epoch 42/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3426 - acc: 0.8839 - val_loss: 0.5766 - val_acc: 0.8224
Epoch 43/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3394 - acc: 0.8871 - val_loss: 0.5708 - val_acc: 0.8258
Epoch 44/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3225 - acc: 0.8916 - val_loss: 0.5630 - val_acc: 0.8310
Epoch 45/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3328 - acc: 0.8868 - val_loss: 0.5868 - val_acc: 0.8240
Epoch 46/50
390/390 [==============================] - 20s 52ms/step - loss: 0.3246 - acc: 0.8934 - val_loss: 0.5798 - val_acc: 0.8269
Epoch 47/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3236 - acc: 0.8930 - val_loss: 0.5623 - val_acc: 0.8275
Epoch 48/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3195 - acc: 0.8934 - val_loss: 0.5855 - val_acc: 0.8286
Epoch 49/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3220 - acc: 0.8910 - val_loss: 0.6214 - val_acc: 0.8206
Epoch 50/50
390/390 [==============================] - 20s 51ms/step - loss: 0.3107 - acc: 0.8946 - val_loss: 0.5770 - val_acc: 0.8274
-------------------------------------------------------------------------------------------------------------------------
Model definition with output channel size and receptive field
-------------------------------------------------------------------------------------------------------------------------
model = Sequential()
model.add(SeparableConv2D(10, 3, 3, border_mode='same', input_shape=(32, 32, 3))) #32
model.add(Activation('relu'))
model.add(BatchNormalization())

model.add(SeparableConv2D(16, 3, 3)) #30
model.add(Activation('relu'))
model.add(Dense(128))
model.add(BatchNormalization())

model.add(SeparableConv2D(16, 3, 3))   #28
model.add(Activation('relu'))
model.add(Dense(512))
model.add(BatchNormalization())

model.add(Dropout(0.3))
model.add(Dense(32))

model.add(MaxPooling2D(pool_size=(2, 2)))                  #14


model.add(SeparableConv2D(10, 1, 1, border_mode='same'))   #14
model.add(Activation('relu'))
model.add(Dense(32))
model.add(BatchNormalization())

model.add(SeparableConv2D(16, 3, 3))                       #12
model.add(Activation('relu'))
model.add(Dense(64))
model.add(BatchNormalization())

model.add(SeparableConv2D(16, 3, 3))                       #10
model.add(Activation('relu'))
model.add(Dense(128))
model.add(BatchNormalization())


model.add(SeparableConv2D(16, 3, 3))                       #8
model.add(Activation('relu'))
model.add(Dense(256))
model.add(BatchNormalization())


model.add(SeparableConv2D(10, 8,use_bias=False))
model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.3))
model.add(Dense(num_classes, activation='softmax'))
model.summary()
